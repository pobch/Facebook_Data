{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data\n",
    "- Remove unwanted '\\r' in 'message' column\n",
    "- Fill NAs with 0 and empty strings\n",
    "- Add label and sub-label column to group the same posts together\n",
    "- Organize data to reduce files' size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pages = ['DramaAdd', 'ejeab', 'cartooneggcat', 'BBCThai', 'khobsanam', '1447102878929950',\n",
    "         'powerofhusbands', 'basementkaraoke', 'cartoon5natee', 'AjahnBuddhadasa', 'Toodsdiary', 'ceclip', 'beargirlfriend',\n",
    "         'jaytherabbitofficial', 'Darlingboredom', 'v.vajiramedhi', '334236760084743', 'kingdomoftigers', 'underbedstar', 'pantipded',\n",
    "         'Pantip.KratooDed', 'nut.ped', '9gaginthai', 'in.one.zaroop']\n",
    "\n",
    "#exclude: 'HighlightsHD.tv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DramaAdd ......... DONE !!\n",
      "ejeab ......... DONE !!\n",
      "cartooneggcat Has no MSG COLUMN !!\n",
      "cartooneggcat ......... DONE !!\n",
      "BBCThai ......... DONE !!\n",
      "khobsanam ......... DONE !!\n",
      "1447102878929950 ......... DONE !!\n",
      "powerofhusbands ......... DONE !!\n",
      "basementkaraoke ......... DONE !!\n",
      "cartoon5natee ......... DONE !!\n",
      "AjahnBuddhadasa ......... DONE !!\n",
      "Toodsdiary ......... DONE !!\n",
      "ceclip ......... DONE !!\n",
      "beargirlfriend ......... DONE !!\n",
      "jaytherabbitofficial ......... DONE !!\n",
      "Darlingboredom ......... DONE !!\n",
      "v.vajiramedhi ......... DONE !!\n",
      "334236760084743 ......... DONE !!\n",
      "kingdomoftigers ......... DONE !!\n",
      "underbedstar ......... DONE !!\n",
      "pantipded ......... DONE !!\n",
      "Pantip.KratooDed ......... DONE !!\n",
      "nut.ped ......... DONE !!\n",
      "9gaginthai ......... DONE !!\n",
      "in.one.zaroop ......... DONE !!\n"
     ]
    }
   ],
   "source": [
    "for page in pages:\n",
    "    df = pd.read_csv(page + '.csv', encoding='utf_8_sig')\n",
    "    pattern = r'(\\r)+'\n",
    "    if 'message' in df.columns:\n",
    "        # there are unwanted '\\r' in 'message' column because of Windows-Python incompatibility \n",
    "        for index, row in df.iterrows():\n",
    "            if pd.isnull(row['message']):\n",
    "                pass\n",
    "            else:\n",
    "                df.loc[index, 'message'] = re.sub(pattern, '', df.loc[index, 'message'])\n",
    "    elif 'link' in df.columns:\n",
    "        print(page + ' Has no MSG COLUMN !!')\n",
    "        df['message'] = ''\n",
    "    else:\n",
    "        raise Exception('What happened ??')\n",
    "    \n",
    "    # fill NA :\n",
    "    df[['comment_count', 'like_count', 'reaction_count', 'share_count']] = \\\n",
    "    df[['comment_count', 'like_count', 'reaction_count', 'share_count']].fillna(0).astype(int)\n",
    "    df[['message', 'link']] = df[['message', 'link']].fillna('').astype(str)\n",
    "    for colname in ['created_time', 'from', 'id', 'time_checked', 'type', 'updated_time']:\n",
    "        df[colname] = df[colname].apply(lambda x: str(x) if pd.notnull(x) else x)\n",
    "    \n",
    "    # create a new dataframe containing 'id', 'message' and 'link' column. Then, drop duplicates :\n",
    "    newdf = df.drop_duplicates(subset=['id', 'message', 'link'])\n",
    "    newdf = newdf.sort_values(by = ['created_time', 'id', 'time_checked'])\n",
    "    newdf.reset_index(drop=True, inplace=True)\n",
    "    # label each row by 'id' :\n",
    "    mapdf = newdf.loc[:, ['id', 'message']].drop_duplicates(subset = 'id')\n",
    "    mapdf.reset_index(drop=True, inplace=True)\n",
    "    mapdf['label1'] = np.arange(len(mapdf)) + 1\n",
    "    newdf = newdf.merge(mapdf[['id', 'label1']], on='id', how='left')\n",
    "    # sub-label each row by 'message' and 'link' :\n",
    "    newdf['label2'] = newdf.groupby('label1').cumcount() + 1\n",
    "    newdf['label2'] = newdf['label2'].astype(int)\n",
    "    # create new csv files containing 'id', 'message', 'link', 'label1' and 'label2' column :\n",
    "    newdf.to_csv(page + 'ID.csv', index=False, encoding='utf_8_sig')\n",
    "    # remove 'message' and 'link' column from original csv files to reduce the size : \n",
    "    df = df.merge(newdf[['id', 'message', 'link', 'label1', 'label2']], on=['id', 'message', 'link'], how='left')\n",
    "    df = df.drop(['message', 'link'], axis=1)\n",
    "    df.to_csv(page + '.csv', index = False, encoding='utf_8_sig')\n",
    "    print(page + ' ......... DONE !!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
